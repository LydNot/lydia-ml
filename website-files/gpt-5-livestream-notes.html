<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>"GPT-5 Livestream Notes" - Lydia ML</title>
    <link rel="stylesheet" href="../styles.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=Crimson+Text:ital,wght@0,400;0,600;1,400&display=swap" rel="stylesheet">
    <style>
        .essay-content {
            max-width: 700px;
            margin: 0 auto;
            padding: 40px 20px;
        }
        
        .essay-header {
            margin-bottom: 40px;
        }
        
        .essay-title {
            font-family: 'Inter', sans-serif;
            font-size: 2.2rem;
            font-weight: 600;
            color: #1a1a1a;
            margin-bottom: 15px;
            line-height: 1.2;
        }
        
        .essay-meta {
            color: #666;
            font-size: 0.9rem;
            margin-bottom: 30px;
        }
        
        .essay-body {
            font-family: 'Crimson Text', Georgia, serif;
            font-size: 1.1rem;
            line-height: 1.7;
            color: #333;
        }
        
        .essay-body h2 {
            font-family: 'Inter', sans-serif;
            font-size: 1.4rem;
            font-weight: 600;
            color: #1a1a1a;
            margin: 40px 0 20px 0;
        }
        
        .essay-body h3 {
            font-family: 'Inter', sans-serif;
            font-size: 1.2rem;
            font-weight: 500;
            color: #1a1a1a;
            margin: 30px 0 15px 0;
        }
        
        .essay-body p {
            margin-bottom: 20px;
        }
        
        .essay-body ul, .essay-body ol {
            margin: 20px 0;
            padding-left: 30px;
        }
        
        .essay-body li {
            margin-bottom: 8px;
        }
        
        .essay-body blockquote {
            border-left: 3px solid #e6e6e6;
            padding-left: 20px;
            margin: 20px 0;
            font-style: italic;
            color: #666;
        }
        
        .essay-body code {
            background-color: #f5f5f5;
            padding: 2px 6px;
            border-radius: 3px;
            font-family: 'Monaco', 'Consolas', monospace;
            font-size: 0.9em;
        }
        
        .essay-body pre {
            background-color: #f5f5f5;
            padding: 20px;
            border-radius: 5px;
            overflow-x: auto;
            margin: 20px 0;
        }
        
        .essay-body pre code {
            background: none;
            padding: 0;
        }
        
        .back-link {
            display: inline-block;
            margin-bottom: 30px;
            color: #666;
            text-decoration: none;
            font-size: 0.9rem;
        }
        
        .back-link:hover {
            color: #1a1a1a;
        }
        
        @media (max-width: 768px) {
            .essay-content {
                padding: 20px 15px;
            }
            
            .essay-title {
                font-size: 1.8rem;
            }
            
            .essay-body {
                font-size: 1rem;
            }
        }
    </style>
</head>
<body>
    <div class="essay-content">
        <a href="../index.html" class="back-link">← Back to home</a>
        
        <div class="essay-header">
            <h1 class="essay-title">"GPT-5 Livestream Notes"</h1>
            <div class="essay-meta">"August 08, 2025" • 3 min read</div>
        </div>
        
        <div class="essay-body">
            <h1>GPT-5 Livestream Notes</h1>
<h3>Low-tech language acquisition</h3>

<p><a href="https://lydianottingham.substack.com/p/gpt-5-livestream-notes/comments"></a></p>

<p>In the morning, I moved some money from my checking account into stocks, just in case this turned out to be big.</p>
<p>My expectations were deflated by the emphasis on traditional, low-tech language acquisition. Musk’s micro-school, Ad Astra, has skipped teaching foreign languages since ~2014 in anticipation of immediate, real-time computer-aided translation.</p>
<p>Here in 2025, Yann Dubois vibecodes an app to help his partner learn French. This ‘sent me’; the theme is evergreen.</p>
<p><a href="https://substackcdn.com/image/fetch/$s_!IE8g!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F04cdcfcb-cbff-4581-9ac9-303582247c45_2727x1426.png"><img alt="Image" src="/images/gpt-5-livestream-notes_img_02.png" /></a></p>
<p>Where’s the spaced repetition? OK, I appreciate this as a vehicle to show off GPT-5’s webdev. But it’s not over yet.</p>
<p>Next it’s over to Ruochen Wang, who is learning Korean (I am curious why). We hear Advanced Voice Mode generate a Korean phrase, speak it slowly, then quickly. </p>
<p><a href="https://substackcdn.com/image/fetch/$s_!whgL!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc516da60-7eb6-4f36-9ade-235ac9ce9d68_2879x1621.png"><img alt="Image" src="/images/gpt-5-livestream-notes_img_03.png" /></a></p>
<p>Again, I get that this is basically a vehicle to show off multimodal capabilities. But anglophone AI researchers still learning foreign languages, in a way that looks remotely like this, makes me feel pretty far from ‘transformative AI’.</p>
<p>Here’s something that would’ve felt very alive:</p>
<ul>
<li>Could they invite on someone who doesn’t speak English and have them contribute / participate as much as everyone else? Negligible latency. That, to me, is a watershed moment. All this ‘basic English to basic foreign language, bijective mapping between lexemes’ is not it.</li>
</ul>
<p>Or (more realistically):</p>
<ul>
<li>Can they change language-learning from active to passive? These use cases count on initiative and discipline. Everyone comes up short sometimes. Where’s the ‘self-activating’ voice mode—one that jumps into practice with you at random / set intervals? Proactive immersion?</li>
</ul>
<p>Or (moreover):</p>
<ul>
<li>Could they demonstrate new frontiers in literature, i.e. how GPT-5 might help an English-speaker quickly internalize, parse, &amp; activate a Russian pattern of thought? That would be showstopping.</li>
</ul>
<p>Some consider it philistine to ignore language-learning just because we have machine translation now. But I think bringing a language to a person who doesn’t speak it is a phenomenal technical challenge. It’s one translators of literature have been facing for decades. How do you capture the space between Russian and English, or Latin and English? <em>This</em> makes me excited—as opposed to something as unscalable and arbitrary as picking one language from many and learning it.</p>
<p>(Tangent) I also think we should probably hack on English as a huge open-source language more. Push it to its limits, bring in the legitimately ‘untranslatable’, and double down on having one Schelling language. I understand we’ve been doing this passively for the past several centuries, but I’ve never seen a serious initiative for the popularization of patterns we’re missing. How do we make it such that you don’t miss out on anything by being solely monoglot? (for any given language?)</p>
<p>Then there are all these bugbear questions about fundamental units of linguistic representation…which I hope to get into in a future post.</p>
<p>I understand that most of the features I discuss above involve ‘wrappers’ on the foundational tech, and that OpenAI’s mission is developing the foundational tech, etc.. I get that it’s basically up to users/developers to flesh out the details here. And good on them for making me think about this, ‘so close yet so far’, etc etc.. I liked this <a href="https://substack.com/@jakeeaton/note/c-140561607">note</a> recently:</p>
<blockquote>
<p>it’s funny how many AI skeptics unconsciously anthropomorphize LLMs in their critiques, like their anger is directed more at a naive zoomer intern who can’t infer the context of your ask, rather than a computer program that can work small miracles if you have the patience to learn how it thinks.</p>
<p>no one gets mad at the limitations of their microwave, or even a stats package, the way they get worked up over a machine in a box that four years ago couldn’t do addition and today wins math olympiads. in that anger is an implicit assumption: that it should know better — and of something on the other end that’s far more than a machine, if not quite yet a soul</p>
</blockquote>
<p><a href="https://lydianottingham.substack.com/p/gpt-5-livestream-notes/comments"></a></p>

<hr />
<p><em>Originally published on <a href="https://lydianottingham.substack.com/p/gpt-5-livestream-notes">Substack</a></em></p>
        </div>
    </div>
</body>
</html>